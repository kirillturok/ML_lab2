{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6mQlb3JMbuYlSnmmrkCZW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirillturok/ML_lab2/blob/main/lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare data"
      ],
      "metadata": {
        "id": "gkuJFbQfmUNS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get notMNIST data"
      ],
      "metadata": {
        "id": "NEdYe7s7nU33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pathlib\n",
        "\n",
        "dataset_url = \"https://commondatastorage.googleapis.com/books1000/notMNIST_large.tar.gz\"\n",
        "dataset_dir = tf.keras.utils.get_file('notMNIST_large.tar', origin=dataset_url, extract=True)\n",
        "dataset_dir = pathlib.Path(dataset_dir).with_suffix('')"
      ],
      "metadata": {
        "id": "JvGGNBiz2DYl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d34100-2716-45e6-9e0b-ee300cd63765"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://commondatastorage.googleapis.com/books1000/notMNIST_large.tar.gz\n",
            "247336696/247336696 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create dataframe"
      ],
      "metadata": {
        "id": "UsdvUhItmgGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "CLASSES = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
        "DATA_COLUMN = 'data'\n",
        "LABELS_COLUMN = 'labels'\n",
        "HASHED_DATA_COLUMN = 'hashed'\n",
        "\n",
        "def get_class_data(folder_path):\n",
        "    result_data = list()\n",
        "    files = os.listdir(folder_path)\n",
        "    for file in files:\n",
        "        image_path = os.path.join(folder_path, file)\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is not None:\n",
        "            result_data.append(img)\n",
        "\n",
        "    return result_data\n",
        "\n",
        "def create_data_frame():\n",
        "    data = list()\n",
        "    labels = list()\n",
        "    for class_item in CLASSES:\n",
        "        class_folder_path = os.path.join(dataset_dir, class_item)\n",
        "        class_data = get_class_data(class_folder_path)\n",
        "\n",
        "        data.extend(class_data)\n",
        "        labels.extend([CLASSES.index(class_item) for _ in range(len(class_data))])\n",
        "\n",
        "    data_frame = pd.DataFrame({DATA_COLUMN: data, LABELS_COLUMN: labels})\n",
        "\n",
        "    return data_frame\n",
        "\n",
        "data_frame = create_data_frame()\n"
      ],
      "metadata": {
        "id": "01tcr2VIepZ_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess data"
      ],
      "metadata": {
        "id": "xZOQg_nln4z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_duplicates(data):\n",
        "    data_bytes = [item.tobytes() for item in data[DATA_COLUMN]]\n",
        "    data[HASHED_DATA_COLUMN] = data_bytes\n",
        "    data.sort_values(HASHED_DATA_COLUMN, inplace=True)\n",
        "    data.drop_duplicates(subset=HASHED_DATA_COLUMN, keep='first', inplace=True)\n",
        "    data.pop(HASHED_DATA_COLUMN)\n",
        "\n",
        "    return data\n",
        "\n",
        "df_no_duplicates = remove_duplicates(data_frame)\n",
        "\n",
        "min_class_count = df_no_duplicates[LABELS_COLUMN].value_counts().min()\n",
        "balanced_df = pd.concat([df_no_duplicates[df_no_duplicates[LABELS_COLUMN] == label].sample(min_class_count) for label in df_no_duplicates[LABELS_COLUMN].unique()])\n",
        "\n",
        "df = balanced_df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "N1p0DFds2mjJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divide into subsamples"
      ],
      "metadata": {
        "id": "eXoZ1vtConov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def divide_into_subsamples(data_frame):\n",
        "    data = np.array(data_frame[DATA_COLUMN].values)\n",
        "    labels = np.array(data_frame[LABELS_COLUMN].values)\n",
        "\n",
        "    data_gray = np.array([rgb2gray(img) for img in data])\n",
        "    data_gray = data_gray.reshape(-1, 28*28)\n",
        "    data_gray = data_gray.astype('float32')\n",
        "\n",
        "    x_train, x_other, y_train, y_other = train_test_split(data_gray, labels, train_size=0.2, random_state = 10)\n",
        "    x_test, x_val, y_test, y_val = train_test_split(x_other, y_other, train_size = 0.5, random_state = 10)\n",
        "\n",
        "    dataset_train = tf.data.Dataset.from_tensor_slices((x_train, to_categorical(y_train, num_classes=10)))\n",
        "    dataset_test = tf.data.Dataset.from_tensor_slices((x_test, to_categorical(y_test, num_classes = 10)))\n",
        "    dataset_val = tf.data.Dataset.from_tensor_slices((x_val, to_categorical(y_val, num_classes = 10)))\n",
        "\n",
        "    return dataset_train, dataset_test, dataset_val\n",
        "\n",
        "dataset_train, dataset_test, dataset_val = divide_into_subsamples(df)\n",
        "\n",
        "dataset_train = dataset_train.batch(BATCH_SIZE)\n",
        "dataset_test = dataset_test.batch(BATCH_SIZE)\n",
        "dataset_val = dataset_val.batch(BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "2L_0IPu3sOzG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "NBwr02sQj_r1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models declaration"
      ],
      "metadata": {
        "id": "vABwlLxMrGu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "input_shape = (28, 28)\n",
        "num_classes = len(CLASSES)\n",
        "\n",
        "# Simple model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(1. / 255),\n",
        "    tf.keras.layers.Flatten(input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "# Regularized model\n",
        "regularized_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(1. / 255),\n",
        "    tf.keras.layers.Flatten(input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(\n",
        "        100,\n",
        "        activation='relu',\n",
        "        kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "regularized_model.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "4NCmLR5v7tWi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters initialization"
      ],
      "metadata": {
        "id": "I-juFhzkuxZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50"
      ],
      "metadata": {
        "id": "JyFJ6Em0u72B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple model processing"
      ],
      "metadata": {
        "id": "ilZaH5XRrMXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    dataset_train,\n",
        "    epochs = EPOCHS,\n",
        "    validation_data = dataset_val)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(dataset_val)\n",
        "print(f'\\nSimple Model\\n\\tTest Accuracy: {test_acc}\\n\\tTest Loss: {test_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge7NvFOfq_BE",
        "outputId": "f156fc86-c00b-488e-c1bc-ebad037075b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.3010 - accuracy: 0.1126 - val_loss: 2.3005 - val_accuracy: 0.0993\n",
            "Epoch 2/50\n",
            "2568/2568 [==============================] - 28s 11ms/step - loss: 2.2999 - accuracy: 0.1235 - val_loss: 2.2994 - val_accuracy: 0.1017\n",
            "Epoch 3/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 2.2988 - accuracy: 0.1345 - val_loss: 2.2982 - val_accuracy: 0.1100\n",
            "Epoch 4/50\n",
            "2568/2568 [==============================] - 17s 6ms/step - loss: 2.2974 - accuracy: 0.1531 - val_loss: 2.2967 - val_accuracy: 0.1428\n",
            "Epoch 5/50\n",
            "2568/2568 [==============================] - 15s 6ms/step - loss: 2.2959 - accuracy: 0.1733 - val_loss: 2.2952 - val_accuracy: 0.1778\n",
            "Epoch 6/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.2943 - accuracy: 0.2001 - val_loss: 2.2934 - val_accuracy: 0.2097\n",
            "Epoch 7/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 2.2925 - accuracy: 0.2288 - val_loss: 2.2915 - val_accuracy: 0.2366\n",
            "Epoch 8/50\n",
            "2568/2568 [==============================] - 16s 6ms/step - loss: 2.2904 - accuracy: 0.2579 - val_loss: 2.2893 - val_accuracy: 0.2598\n",
            "Epoch 9/50\n",
            "2568/2568 [==============================] - 16s 6ms/step - loss: 2.2881 - accuracy: 0.2850 - val_loss: 2.2869 - val_accuracy: 0.2859\n",
            "Epoch 10/50\n",
            "2568/2568 [==============================] - 16s 6ms/step - loss: 2.2854 - accuracy: 0.3109 - val_loss: 2.2841 - val_accuracy: 0.3197\n",
            "Epoch 11/50\n",
            "2568/2568 [==============================] - 16s 6ms/step - loss: 2.2825 - accuracy: 0.3346 - val_loss: 2.2809 - val_accuracy: 0.3613\n",
            "Epoch 12/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.2790 - accuracy: 0.3592 - val_loss: 2.2772 - val_accuracy: 0.4020\n",
            "Epoch 13/50\n",
            "2568/2568 [==============================] - 16s 6ms/step - loss: 2.2751 - accuracy: 0.3828 - val_loss: 2.2730 - val_accuracy: 0.4379\n",
            "Epoch 14/50\n",
            "2568/2568 [==============================] - 16s 6ms/step - loss: 2.2706 - accuracy: 0.4052 - val_loss: 2.2682 - val_accuracy: 0.4703\n",
            "Epoch 15/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 2.2654 - accuracy: 0.4273 - val_loss: 2.2626 - val_accuracy: 0.4966\n",
            "Epoch 16/50\n",
            "2568/2568 [==============================] - 20s 8ms/step - loss: 2.2593 - accuracy: 0.4481 - val_loss: 2.2561 - val_accuracy: 0.5232\n",
            "Epoch 17/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 2.2524 - accuracy: 0.4680 - val_loss: 2.2487 - val_accuracy: 0.5519\n",
            "Epoch 18/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.2444 - accuracy: 0.4849 - val_loss: 2.2401 - val_accuracy: 0.5761\n",
            "Epoch 19/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.2352 - accuracy: 0.5002 - val_loss: 2.2303 - val_accuracy: 0.6017\n",
            "Epoch 20/50\n",
            "2568/2568 [==============================] - 16s 6ms/step - loss: 2.2246 - accuracy: 0.5130 - val_loss: 2.2191 - val_accuracy: 0.6254\n",
            "Epoch 21/50\n",
            "2568/2568 [==============================] - 16s 6ms/step - loss: 2.2126 - accuracy: 0.5255 - val_loss: 2.2063 - val_accuracy: 0.6418\n",
            "Epoch 22/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 2.1990 - accuracy: 0.5357 - val_loss: 2.1918 - val_accuracy: 0.6502\n",
            "Epoch 23/50\n",
            "2568/2568 [==============================] - 17s 6ms/step - loss: 2.1836 - accuracy: 0.5434 - val_loss: 2.1755 - val_accuracy: 0.6541\n",
            "Epoch 24/50\n",
            "2568/2568 [==============================] - 16s 6ms/step - loss: 2.1664 - accuracy: 0.5491 - val_loss: 2.1572 - val_accuracy: 0.6527\n",
            "Epoch 25/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.1471 - accuracy: 0.5539 - val_loss: 2.1370 - val_accuracy: 0.6490\n",
            "Epoch 26/50\n",
            "2568/2568 [==============================] - 17s 6ms/step - loss: 2.1258 - accuracy: 0.5572 - val_loss: 2.1147 - val_accuracy: 0.6448\n",
            "Epoch 27/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 2.1024 - accuracy: 0.5607 - val_loss: 2.0903 - val_accuracy: 0.6399\n",
            "Epoch 28/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 2.0770 - accuracy: 0.5631 - val_loss: 2.0640 - val_accuracy: 0.6356\n",
            "Epoch 29/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.0497 - accuracy: 0.5652 - val_loss: 2.0359 - val_accuracy: 0.6316\n",
            "Epoch 30/50\n",
            "2568/2568 [==============================] - 27s 11ms/step - loss: 2.0207 - accuracy: 0.5669 - val_loss: 2.0060 - val_accuracy: 0.6286\n",
            "Epoch 31/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 1.9901 - accuracy: 0.5692 - val_loss: 1.9748 - val_accuracy: 0.6260\n",
            "Epoch 32/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.9581 - accuracy: 0.5719 - val_loss: 1.9423 - val_accuracy: 0.6241\n",
            "Epoch 33/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.9250 - accuracy: 0.5747 - val_loss: 1.9089 - val_accuracy: 0.6236\n",
            "Epoch 34/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 1.8911 - accuracy: 0.5781 - val_loss: 1.8747 - val_accuracy: 0.6243\n",
            "Epoch 35/50\n",
            "2568/2568 [==============================] - 16s 6ms/step - loss: 1.8566 - accuracy: 0.5815 - val_loss: 1.8401 - val_accuracy: 0.6246\n",
            "Epoch 36/50\n",
            "2568/2568 [==============================] - 17s 6ms/step - loss: 1.8218 - accuracy: 0.5859 - val_loss: 1.8053 - val_accuracy: 0.6259\n",
            "Epoch 37/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 1.7868 - accuracy: 0.5906 - val_loss: 1.7705 - val_accuracy: 0.6278\n",
            "Epoch 38/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 1.7519 - accuracy: 0.5951 - val_loss: 1.7359 - val_accuracy: 0.6299\n",
            "Epoch 39/50\n",
            "2568/2568 [==============================] - 16s 6ms/step - loss: 1.7174 - accuracy: 0.6006 - val_loss: 1.7017 - val_accuracy: 0.6320\n",
            "Epoch 40/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 1.6833 - accuracy: 0.6062 - val_loss: 1.6681 - val_accuracy: 0.6346\n",
            "Epoch 41/50\n",
            "2568/2568 [==============================] - 16s 6ms/step - loss: 1.6499 - accuracy: 0.6119 - val_loss: 1.6352 - val_accuracy: 0.6378\n",
            "Epoch 42/50\n",
            "2568/2568 [==============================] - 16s 6ms/step - loss: 1.6173 - accuracy: 0.6174 - val_loss: 1.6032 - val_accuracy: 0.6410\n",
            "Epoch 43/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 1.5857 - accuracy: 0.6228 - val_loss: 1.5722 - val_accuracy: 0.6442\n",
            "Epoch 44/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.5551 - accuracy: 0.6282 - val_loss: 1.5423 - val_accuracy: 0.6476\n",
            "Epoch 45/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 1.5256 - accuracy: 0.6337 - val_loss: 1.5135 - val_accuracy: 0.6505\n",
            "Epoch 46/50\n",
            "2568/2568 [==============================] - 20s 8ms/step - loss: 1.4972 - accuracy: 0.6386 - val_loss: 1.4860 - val_accuracy: 0.6538\n",
            "Epoch 47/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 1.4701 - accuracy: 0.6431 - val_loss: 1.4596 - val_accuracy: 0.6571\n",
            "Epoch 48/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 1.4441 - accuracy: 0.6477 - val_loss: 1.4344 - val_accuracy: 0.6603\n",
            "Epoch 49/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 1.4194 - accuracy: 0.6522 - val_loss: 1.4104 - val_accuracy: 0.6635\n",
            "Epoch 50/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 1.3959 - accuracy: 0.6569 - val_loss: 1.3876 - val_accuracy: 0.6666\n",
            "5136/5136 [==============================] - 12s 2ms/step - loss: 1.3876 - accuracy: 0.6666\n",
            "\n",
            "Simple Model\n",
            "\tTest Accuracy: 0.666634202003479\n",
            "\tTest Loss: 1.3875747919082642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regularized model processing"
      ],
      "metadata": {
        "id": "i7K6G0bGsUHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regularized_model.fit(\n",
        "    dataset_train,\n",
        "    epochs = EPOCHS,\n",
        "    validation_data = dataset_val)\n",
        "\n",
        "test_loss, test_acc = regularized_model.evaluate(dataset_val)\n",
        "print(f'\\nRegularized Model\\n\\tTest Accuracy: {test_acc}\\n\\tTest Loss: {test_loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsH34V6qsZdt",
        "outputId": "067dc912-a6c5-465e-8d74-393e29cc2841"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2568/2568 [==============================] - 20s 7ms/step - loss: 2.4697 - accuracy: 0.1285 - val_loss: 2.4607 - val_accuracy: 0.0989\n",
            "Epoch 2/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.4524 - accuracy: 0.1291 - val_loss: 2.4443 - val_accuracy: 0.1140\n",
            "Epoch 3/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 2.4367 - accuracy: 0.1400 - val_loss: 2.4293 - val_accuracy: 0.1320\n",
            "Epoch 4/50\n",
            "2568/2568 [==============================] - 36s 14ms/step - loss: 2.4225 - accuracy: 0.1476 - val_loss: 2.4157 - val_accuracy: 0.1161\n",
            "Epoch 5/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.4095 - accuracy: 0.1555 - val_loss: 2.4034 - val_accuracy: 0.1913\n",
            "Epoch 6/50\n",
            "2568/2568 [==============================] - 20s 8ms/step - loss: 2.3977 - accuracy: 0.1718 - val_loss: 2.3921 - val_accuracy: 0.2326\n",
            "Epoch 7/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.3869 - accuracy: 0.1821 - val_loss: 2.3818 - val_accuracy: 0.3193\n",
            "Epoch 8/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.3770 - accuracy: 0.1888 - val_loss: 2.3723 - val_accuracy: 0.2904\n",
            "Epoch 9/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 2.3679 - accuracy: 0.2023 - val_loss: 2.3636 - val_accuracy: 0.2298\n",
            "Epoch 10/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.3594 - accuracy: 0.2062 - val_loss: 2.3555 - val_accuracy: 0.3864\n",
            "Epoch 11/50\n",
            "2568/2568 [==============================] - 20s 8ms/step - loss: 2.3517 - accuracy: 0.2183 - val_loss: 2.3480 - val_accuracy: 0.3751\n",
            "Epoch 12/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.3444 - accuracy: 0.2286 - val_loss: 2.3409 - val_accuracy: 0.4426\n",
            "Epoch 13/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 2.3377 - accuracy: 0.2430 - val_loss: 2.3343 - val_accuracy: 0.4275\n",
            "Epoch 14/50\n",
            "2568/2568 [==============================] - 19s 8ms/step - loss: 2.3312 - accuracy: 0.2556 - val_loss: 2.3280 - val_accuracy: 0.4356\n",
            "Epoch 15/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.3250 - accuracy: 0.2612 - val_loss: 2.3220 - val_accuracy: 0.4214\n",
            "Epoch 16/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 2.3191 - accuracy: 0.2667 - val_loss: 2.3160 - val_accuracy: 0.4884\n",
            "Epoch 17/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 2.3132 - accuracy: 0.2790 - val_loss: 2.3104 - val_accuracy: 0.4490\n",
            "Epoch 18/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 2.3076 - accuracy: 0.2838 - val_loss: 2.3047 - val_accuracy: 0.4839\n",
            "Epoch 19/50\n",
            "2568/2568 [==============================] - 30s 12ms/step - loss: 2.3019 - accuracy: 0.2940 - val_loss: 2.2991 - val_accuracy: 0.4794\n",
            "Epoch 20/50\n",
            "2568/2568 [==============================] - 20s 8ms/step - loss: 2.2965 - accuracy: 0.2971 - val_loss: 2.2932 - val_accuracy: 0.4952\n",
            "Epoch 21/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.2907 - accuracy: 0.3091 - val_loss: 2.2875 - val_accuracy: 0.4755\n",
            "Epoch 22/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.2848 - accuracy: 0.3085 - val_loss: 2.2815 - val_accuracy: 0.4818\n",
            "Epoch 23/50\n",
            "2568/2568 [==============================] - 19s 8ms/step - loss: 2.2788 - accuracy: 0.3180 - val_loss: 2.2753 - val_accuracy: 0.4533\n",
            "Epoch 24/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 2.2724 - accuracy: 0.3161 - val_loss: 2.2688 - val_accuracy: 0.5006\n",
            "Epoch 25/50\n",
            "2568/2568 [==============================] - 21s 8ms/step - loss: 2.2661 - accuracy: 0.3260 - val_loss: 2.2621 - val_accuracy: 0.5098\n",
            "Epoch 26/50\n",
            "2568/2568 [==============================] - 19s 8ms/step - loss: 2.2593 - accuracy: 0.3244 - val_loss: 2.2550 - val_accuracy: 0.4868\n",
            "Epoch 27/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.2522 - accuracy: 0.3323 - val_loss: 2.2477 - val_accuracy: 0.4838\n",
            "Epoch 28/50\n",
            "2568/2568 [==============================] - 20s 8ms/step - loss: 2.2445 - accuracy: 0.3340 - val_loss: 2.2399 - val_accuracy: 0.5339\n",
            "Epoch 29/50\n",
            "2568/2568 [==============================] - 29s 11ms/step - loss: 2.2367 - accuracy: 0.3412 - val_loss: 2.2316 - val_accuracy: 0.4638\n",
            "Epoch 30/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.2291 - accuracy: 0.3389 - val_loss: 2.2231 - val_accuracy: 0.5171\n",
            "Epoch 31/50\n",
            "2568/2568 [==============================] - 28s 11ms/step - loss: 2.2204 - accuracy: 0.3473 - val_loss: 2.2142 - val_accuracy: 0.4961\n",
            "Epoch 32/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.2114 - accuracy: 0.3475 - val_loss: 2.2048 - val_accuracy: 0.4984\n",
            "Epoch 33/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 2.2020 - accuracy: 0.3530 - val_loss: 2.1952 - val_accuracy: 0.5136\n",
            "Epoch 34/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.1923 - accuracy: 0.3601 - val_loss: 2.1850 - val_accuracy: 0.5211\n",
            "Epoch 35/50\n",
            "2568/2568 [==============================] - 20s 8ms/step - loss: 2.1829 - accuracy: 0.3627 - val_loss: 2.1749 - val_accuracy: 0.4964\n",
            "Epoch 36/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 2.1729 - accuracy: 0.3668 - val_loss: 2.1640 - val_accuracy: 0.5140\n",
            "Epoch 37/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 2.1624 - accuracy: 0.3687 - val_loss: 2.1534 - val_accuracy: 0.5198\n",
            "Epoch 38/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.1513 - accuracy: 0.3728 - val_loss: 2.1421 - val_accuracy: 0.5091\n",
            "Epoch 39/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.1412 - accuracy: 0.3810 - val_loss: 2.1308 - val_accuracy: 0.5179\n",
            "Epoch 40/50\n",
            "2568/2568 [==============================] - 20s 8ms/step - loss: 2.1307 - accuracy: 0.3848 - val_loss: 2.1195 - val_accuracy: 0.5295\n",
            "Epoch 41/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 2.1193 - accuracy: 0.3889 - val_loss: 2.1081 - val_accuracy: 0.5325\n",
            "Epoch 42/50\n",
            "2568/2568 [==============================] - 19s 8ms/step - loss: 2.1088 - accuracy: 0.3951 - val_loss: 2.0967 - val_accuracy: 0.5397\n",
            "Epoch 43/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 2.0985 - accuracy: 0.4045 - val_loss: 2.0853 - val_accuracy: 0.5389\n",
            "Epoch 44/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.0870 - accuracy: 0.4091 - val_loss: 2.0735 - val_accuracy: 0.5475\n",
            "Epoch 45/50\n",
            "2568/2568 [==============================] - 22s 9ms/step - loss: 2.0755 - accuracy: 0.4154 - val_loss: 2.0621 - val_accuracy: 0.5522\n",
            "Epoch 46/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.0653 - accuracy: 0.4214 - val_loss: 2.0499 - val_accuracy: 0.5556\n",
            "Epoch 47/50\n",
            "2568/2568 [==============================] - 30s 12ms/step - loss: 2.0536 - accuracy: 0.4282 - val_loss: 2.0377 - val_accuracy: 0.5582\n",
            "Epoch 48/50\n",
            "2568/2568 [==============================] - 19s 8ms/step - loss: 2.0439 - accuracy: 0.4354 - val_loss: 2.0263 - val_accuracy: 0.5637\n",
            "Epoch 49/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 2.0321 - accuracy: 0.4396 - val_loss: 2.0148 - val_accuracy: 0.5598\n",
            "Epoch 50/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 2.0209 - accuracy: 0.4483 - val_loss: 2.0030 - val_accuracy: 0.5751\n",
            "5136/5136 [==============================] - 11s 2ms/step - loss: 2.0030 - accuracy: 0.5751\n",
            "\n",
            "Regularized Model\n",
            "\tTest Accuracy: 0.5750839710235596\n",
            "\tTest Loss: 2.002985954284668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dynamic model processing"
      ],
      "metadata": {
        "id": "q6u06FQuuF3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "INITIAL_LEARNING_RATE = 0.01\n",
        "MIN_LEARNING_RATE = 1e-6\n",
        "DECAY_STEPS = 12000\n",
        "DECAY_RATE = 0.8\n",
        "\n",
        "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate = INITIAL_LEARNING_RATE,\n",
        "    decay_steps = DECAY_STEPS,\n",
        "    decay_rate = DECAY_RATE,\n",
        "    staircase = True)\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor = 'val_loss',\n",
        "    factor = 0.1,\n",
        "    patience = 6,\n",
        "    verbose = 1,\n",
        "    min_lr = MIN_LEARNING_RATE)\n",
        "\n",
        "regularized_model.fit(\n",
        "    dataset_train,\n",
        "    validation_data = dataset_val,\n",
        "    epochs = EPOCHS,\n",
        "    callbacks = reduce_lr,\n",
        "    verbose = 1)\n",
        "\n",
        "test_loss, test_acc = regularized_model.evaluate(dataset_val)\n",
        "print(f'\\nDynamic Model\\n\\tTest Accuracy: {test_acc}\\n\\tTest Loss: {test_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo2pfCVx_daB",
        "outputId": "423391c3-b430-43c6-c4ed-5f5e2e43373e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 2.0099 - accuracy: 0.4551 - val_loss: 1.9915 - val_accuracy: 0.5785 - lr: 0.0100\n",
            "Epoch 2/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 2.0007 - accuracy: 0.4593 - val_loss: 1.9801 - val_accuracy: 0.5851 - lr: 0.0100\n",
            "Epoch 3/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 1.9890 - accuracy: 0.4688 - val_loss: 1.9696 - val_accuracy: 0.5949 - lr: 0.0100\n",
            "Epoch 4/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.9786 - accuracy: 0.4721 - val_loss: 1.9572 - val_accuracy: 0.5874 - lr: 0.0100\n",
            "Epoch 5/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 1.9674 - accuracy: 0.4791 - val_loss: 1.9458 - val_accuracy: 0.5882 - lr: 0.0100\n",
            "Epoch 6/50\n",
            "2568/2568 [==============================] - 19s 8ms/step - loss: 1.9573 - accuracy: 0.4851 - val_loss: 1.9356 - val_accuracy: 0.6024 - lr: 0.0100\n",
            "Epoch 7/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 1.9469 - accuracy: 0.4894 - val_loss: 1.9241 - val_accuracy: 0.5990 - lr: 0.0100\n",
            "Epoch 8/50\n",
            "2568/2568 [==============================] - 20s 8ms/step - loss: 1.9379 - accuracy: 0.4944 - val_loss: 1.9142 - val_accuracy: 0.6087 - lr: 0.0100\n",
            "Epoch 9/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 1.9290 - accuracy: 0.4983 - val_loss: 1.9034 - val_accuracy: 0.6074 - lr: 0.0100\n",
            "Epoch 10/50\n",
            "2568/2568 [==============================] - 20s 8ms/step - loss: 1.9174 - accuracy: 0.5048 - val_loss: 1.8930 - val_accuracy: 0.6123 - lr: 0.0100\n",
            "Epoch 11/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.9083 - accuracy: 0.5096 - val_loss: 1.8817 - val_accuracy: 0.6216 - lr: 0.0100\n",
            "Epoch 12/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 1.8994 - accuracy: 0.5129 - val_loss: 1.8729 - val_accuracy: 0.6194 - lr: 0.0100\n",
            "Epoch 13/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 1.8910 - accuracy: 0.5198 - val_loss: 1.8634 - val_accuracy: 0.6114 - lr: 0.0100\n",
            "Epoch 14/50\n",
            "2568/2568 [==============================] - 19s 8ms/step - loss: 1.8816 - accuracy: 0.5208 - val_loss: 1.8545 - val_accuracy: 0.6199 - lr: 0.0100\n",
            "Epoch 15/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.8726 - accuracy: 0.5281 - val_loss: 1.8449 - val_accuracy: 0.6213 - lr: 0.0100\n",
            "Epoch 16/50\n",
            "2568/2568 [==============================] - 30s 12ms/step - loss: 1.8622 - accuracy: 0.5299 - val_loss: 1.8346 - val_accuracy: 0.6172 - lr: 0.0100\n",
            "Epoch 17/50\n",
            "2568/2568 [==============================] - 21s 8ms/step - loss: 1.8539 - accuracy: 0.5340 - val_loss: 1.8257 - val_accuracy: 0.6125 - lr: 0.0100\n",
            "Epoch 18/50\n",
            "2568/2568 [==============================] - 20s 8ms/step - loss: 1.8461 - accuracy: 0.5392 - val_loss: 1.8183 - val_accuracy: 0.6198 - lr: 0.0100\n",
            "Epoch 19/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 1.8381 - accuracy: 0.5429 - val_loss: 1.8080 - val_accuracy: 0.6214 - lr: 0.0100\n",
            "Epoch 20/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 1.8294 - accuracy: 0.5453 - val_loss: 1.8006 - val_accuracy: 0.6343 - lr: 0.0100\n",
            "Epoch 21/50\n",
            "2568/2568 [==============================] - 20s 8ms/step - loss: 1.8224 - accuracy: 0.5468 - val_loss: 1.7916 - val_accuracy: 0.6355 - lr: 0.0100\n",
            "Epoch 22/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.8149 - accuracy: 0.5524 - val_loss: 1.7831 - val_accuracy: 0.6270 - lr: 0.0100\n",
            "Epoch 23/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.8074 - accuracy: 0.5559 - val_loss: 1.7748 - val_accuracy: 0.6331 - lr: 0.0100\n",
            "Epoch 24/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.8016 - accuracy: 0.5574 - val_loss: 1.7669 - val_accuracy: 0.6389 - lr: 0.0100\n",
            "Epoch 25/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.7933 - accuracy: 0.5612 - val_loss: 1.7607 - val_accuracy: 0.6310 - lr: 0.0100\n",
            "Epoch 26/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 1.7860 - accuracy: 0.5649 - val_loss: 1.7526 - val_accuracy: 0.6336 - lr: 0.0100\n",
            "Epoch 27/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 1.7794 - accuracy: 0.5643 - val_loss: 1.7443 - val_accuracy: 0.6385 - lr: 0.0100\n",
            "Epoch 28/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.7718 - accuracy: 0.5684 - val_loss: 1.7357 - val_accuracy: 0.6481 - lr: 0.0100\n",
            "Epoch 29/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 1.7668 - accuracy: 0.5742 - val_loss: 1.7321 - val_accuracy: 0.6356 - lr: 0.0100\n",
            "Epoch 30/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 1.7598 - accuracy: 0.5755 - val_loss: 1.7250 - val_accuracy: 0.6493 - lr: 0.0100\n",
            "Epoch 31/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.7526 - accuracy: 0.5775 - val_loss: 1.7172 - val_accuracy: 0.6475 - lr: 0.0100\n",
            "Epoch 32/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 1.7471 - accuracy: 0.5814 - val_loss: 1.7136 - val_accuracy: 0.6399 - lr: 0.0100\n",
            "Epoch 33/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 1.7398 - accuracy: 0.5839 - val_loss: 1.7054 - val_accuracy: 0.6409 - lr: 0.0100\n",
            "Epoch 34/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.7361 - accuracy: 0.5843 - val_loss: 1.7004 - val_accuracy: 0.6378 - lr: 0.0100\n",
            "Epoch 35/50\n",
            "2568/2568 [==============================] - 19s 8ms/step - loss: 1.7286 - accuracy: 0.5900 - val_loss: 1.6935 - val_accuracy: 0.6526 - lr: 0.0100\n",
            "Epoch 36/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.7231 - accuracy: 0.5900 - val_loss: 1.6859 - val_accuracy: 0.6510 - lr: 0.0100\n",
            "Epoch 37/50\n",
            "2568/2568 [==============================] - 19s 8ms/step - loss: 1.7184 - accuracy: 0.5920 - val_loss: 1.6790 - val_accuracy: 0.6591 - lr: 0.0100\n",
            "Epoch 38/50\n",
            "2568/2568 [==============================] - 19s 8ms/step - loss: 1.7137 - accuracy: 0.5947 - val_loss: 1.6738 - val_accuracy: 0.6590 - lr: 0.0100\n",
            "Epoch 39/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 1.7077 - accuracy: 0.5960 - val_loss: 1.6682 - val_accuracy: 0.6576 - lr: 0.0100\n",
            "Epoch 40/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 1.7031 - accuracy: 0.5987 - val_loss: 1.6629 - val_accuracy: 0.6569 - lr: 0.0100\n",
            "Epoch 41/50\n",
            "2568/2568 [==============================] - 17s 7ms/step - loss: 1.6981 - accuracy: 0.6002 - val_loss: 1.6593 - val_accuracy: 0.6558 - lr: 0.0100\n",
            "Epoch 42/50\n",
            "2568/2568 [==============================] - 17s 6ms/step - loss: 1.6911 - accuracy: 0.6028 - val_loss: 1.6555 - val_accuracy: 0.6547 - lr: 0.0100\n",
            "Epoch 43/50\n",
            "2568/2568 [==============================] - 29s 11ms/step - loss: 1.6873 - accuracy: 0.6027 - val_loss: 1.6488 - val_accuracy: 0.6599 - lr: 0.0100\n",
            "Epoch 44/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.6841 - accuracy: 0.6048 - val_loss: 1.6426 - val_accuracy: 0.6675 - lr: 0.0100\n",
            "Epoch 45/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.6775 - accuracy: 0.6070 - val_loss: 1.6387 - val_accuracy: 0.6653 - lr: 0.0100\n",
            "Epoch 46/50\n",
            "2568/2568 [==============================] - 19s 7ms/step - loss: 1.6732 - accuracy: 0.6067 - val_loss: 1.6333 - val_accuracy: 0.6626 - lr: 0.0100\n",
            "Epoch 47/50\n",
            "2568/2568 [==============================] - 16s 6ms/step - loss: 1.6683 - accuracy: 0.6118 - val_loss: 1.6284 - val_accuracy: 0.6625 - lr: 0.0100\n",
            "Epoch 48/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.6631 - accuracy: 0.6118 - val_loss: 1.6223 - val_accuracy: 0.6661 - lr: 0.0100\n",
            "Epoch 49/50\n",
            "2568/2568 [==============================] - 20s 8ms/step - loss: 1.6576 - accuracy: 0.6130 - val_loss: 1.6178 - val_accuracy: 0.6633 - lr: 0.0100\n",
            "Epoch 50/50\n",
            "2568/2568 [==============================] - 18s 7ms/step - loss: 1.6540 - accuracy: 0.6172 - val_loss: 1.6125 - val_accuracy: 0.6701 - lr: 0.0100\n",
            "5136/5136 [==============================] - 13s 2ms/step - loss: 1.6125 - accuracy: 0.6701\n",
            "\n",
            "Dynamic Model\n",
            "\tTest Accuracy: 0.6701270341873169\n",
            "\tTest Loss: 1.6124968528747559\n"
          ]
        }
      ]
    }
  ]
}